{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% measure accuracy\n",
    "import os\n",
    "import gc\n",
    "import sys\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.adam as adam\n",
    "import torch.optim.lr_scheduler\n",
    "torch.backends.cudnn.benchmark=True\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dataset\n",
    "from models.AlexNet import *\n",
    "from models.ResNet import *\n",
    "import csv\n",
    "from os.path import expanduser\n",
    "\n",
    "from ClassificationCleaning import clean\n",
    "from importlib import reload\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fahad/anaconda3/lib/python3.7/site-packages/torch/utils/data/sampler.py:115: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.weights = torch.tensor(weights, dtype=torch.double)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1472 correct from 1472 total \n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000  # 15 + ii*7\n",
    "output_period = 50\n",
    "batch_size = 50\n",
    "\n",
    "sModelPath='/home/fahad/data/streetContext/streetImages/SF/modelRelated/models/resnet18_poi/resnet18_afterCleaning.932'\n",
    "sDataPath = '/home/fahad/data/streetContext/streetImages/SF/modelRelated/data/resnetPOI/'\n",
    "\n",
    "os.chdir('/home/fahad/git/streetContext/code/resnet')\n",
    "\n",
    "# setup the device for running\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader, val_loader = dataset.get_data_loaders(batch_size)\n",
    "\n",
    "nClasses = 11\n",
    "# model = torchvision.models.inception_v3(num_classes=11,aux_logits=False)\n",
    "model = resnet_18()  # alexnet()# resnet_34()\n",
    "# torchvision.models.ince\n",
    "# this allows for the model to proceed with training after the starting point\n",
    "\n",
    "#loading the model\n",
    "model.load_state_dict(torch.load(sModelPath))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "home = expanduser(\"~\")\n",
    "\n",
    "\n",
    "total,correct=0,0\n",
    "setSize = loss = i = 0;\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "for batch_num, (val_inputs, val_labels) in enumerate(val_loader, 1):\n",
    "\n",
    "    gc.collect()\n",
    "    val_inputs = val_inputs.to(device)\n",
    "    val_labels = val_labels.to(device)\n",
    "    val_outputs = model(val_inputs)\n",
    "    val_predictions = torch.argmax(val_outputs, 1)\n",
    "    \n",
    "    for i in range(len(val_predictions)):\n",
    "        if val_predictions[i]==val_labels[i]:\n",
    "            correct+=1;\n",
    "        total+=1\n",
    "print('{} correct from {} total '.format(correct,total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
